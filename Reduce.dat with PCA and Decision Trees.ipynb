{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating reduce.dat with PCA and Decision Trees\n",
    "\n",
    "So you've already got ready.dat, but you want to ditch her for the hotter, younger and slimmer reduce.dat?\n",
    "\n",
    "Well, you've come to the right place!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataload import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = load_object('ready.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4408587, 56) (489844, 56)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,x_test.shape)\n",
    "# yes, this is supposed to be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First get list of columns that account for variance of minority attack types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cats_importance(cats_train, target):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    dt = DecisionTreeClassifier(max_depth=10, random_state=4129)\n",
    "    dt.fit(cats_train, y_train.attack_type == target)\n",
    "    return pd.DataFrame(dt.feature_importances_, columns=['imp']).sort_values(by='imp', axis=0, ascending=False).iloc[:20]\n",
    "# [cats_importance(cats_train, i) for i in ['normal','dos','probe','r2l','u2r']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 6, 10, 14, 17, 18, 27, 30, 31]\n"
     ]
    }
   ],
   "source": [
    "r2l_impts = cats_importance(x_train[:,0:37], 'r2l')\n",
    "u2r_impts = cats_importance(x_train[:,0:37], 'u2r')\n",
    "t_percent_var = 0.0\n",
    "col_list = []\n",
    "for i in range(20):\n",
    "    col_list.append(r2l_impts.index[i])\n",
    "    t_percent_var += r2l_impts.iloc[i, 0]\n",
    "    if(t_percent_var > 0.85):\n",
    "        break\n",
    "t_percent_var = 0.0\n",
    "for i in range(20):\n",
    "    if(u2r_impts.index[i] not in col_list):\n",
    "        col_list.append(u2r_impts.index[i])\n",
    "#    else:\n",
    "#        print('duplicate')\n",
    "    t_percent_var += u2r_impts.iloc[i, 0]\n",
    "    if(t_percent_var > 0.85):\n",
    "        break\n",
    "col_list.sort()\n",
    "print(col_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, top 5 PCA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59967437, 0.2070158 , 0.12038367, 0.02078111, 0.01783307])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get list of column that accounts for variance of minority attack types\n",
    "## Get top 5 PCA components\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 5, random_state = 4129)\n",
    "pca_result = pca.fit_transform(x_train[:,0:37])\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create new x_train_new with PCA component\n",
    "x_train_new = pca_result.copy()\n",
    "## Add list of minority attack types columns to x_train_new\n",
    "for i in col_list:\n",
    "    x_train_new = np.concatenate((x_train_new, x_train[:, i:i+1]), axis = 1)\n",
    "## Add remaining columns not within first 37 of x_train\n",
    "x_train_new = np.concatenate((x_train_new, x_train[:, 37:]), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4408587, 35)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(489844, 35)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## do same for x_test\n",
    "pca_result_test = pca.transform(x_test[:,0:37])\n",
    "x_test_new = pca_result_test.copy()\n",
    "for i in col_list:\n",
    "    x_test_new = np.concatenate((x_test_new, x_test[:, i:i+1]), axis = 1)\n",
    "x_test_new = np.concatenate((x_test_new, x_test[:, 37:]), axis = 1)\n",
    "\n",
    "x_test_new.shape\n",
    "# the key question here is: are there features which are highly correlated with the rare classes?\n",
    "# we should use such features directly in the classifiers -- don't pass them thru PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object([x_train_new, x_test_new, y_train, y_test],'reduce.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
